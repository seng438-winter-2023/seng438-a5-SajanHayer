**SENG 438- Software Testing, Reliability, and Quality**

**Lab. Report \#5 â€“ Software Reliability Assessment**

| Group \#:       |   |
|-----------------|---|
| Student Names: |  Manraj Singh   |
|                |  Sajan Hayer   |
|                |  Noor Nawaz   |
|                |  Ahmad Elshiltawi   |

# Introduction
This lab included two parts: reliability assessment with Growth testing and with a Demonstration Chart. Through part one, students learned to explore failure reliability growth testing with the use of tools such as CSFRAT and CSTRAT  which demonstrate failures over a period of time. The second part of this lab involved using the excel sheet to produce Reliability demonstration Charts which allows us to analyze and compare failure data to an acceptable MTTF. Additionally, this lab also introduced to us the concept of failure data which is critical to analyze f for SUTS as it can aid us in determining how to prevent future failures and see if the SUT will need further development. 

# 

# Assessment Using Reliability Growth Testing (Part 1)
The Failure Data Set that our group decided to use was the J5.dat file that was within the Failure count  folder in the Failure data sets provided by the lab. We formatted this data into an excel sheet with info provided to be used with the CSFRAT tool. For the RDC document we had to change the data around to function for the excel sheet that was provided. 

**All models applied to our failure data:**
(image)

**Model ranking:**
(image rank)
Based on the model ranking through our CSFRAT application we can see that by ordering the Log-Likelihood in ascending order we can see which model will work the best for our failure data. In the picture above we can see that the model that would work best for our data is S. 

**Result of Range Analysis (Which Part of the data we should use):**
After completing the comparison of the models a range analysis using the laplace test or an equivalent method was to be used. This would determine the useful range of data that we can use for our next couple steps. This laplace test was to be done either using CSFRAT or using CARSE to determine the valid range. We were not able to do this since CSFRAT does not have laplace testing tools built into it along with CARSE not being able to run on any of our computers this results in us having to use the whole range of data to be treated as valid (no testing was able to be done). Thus we had a range analysis from 0-14 within our graph. Ideally a laplace test was to be done Any range for the data above +2 would be considered reliability decrease , while any value below -2 for the laplace would be increasing reliability (and any reliability model may be used). In between, any value between -2 and +2 would be classified as stable reliability. Most importantly, any data where the laplace value is greater than -2 should be omitted in the range. As stated earlier since we were not able to run this test, we left the range/interval unchanged. 

**MVF and Intensity Graphs:**
S MVF Plot:
(mvf image)

S intensity plot:
(intestity image)

**A discussion on decision making given a target failure rate:**
Reliability Graph Prediction:
(prediction graph)

To decide on a target failure rate we used the CSFRAT tool to help us predict at which interval this target would be hit, we did not use any other tools as none of them were able to function on any of our laptops. After using the CSFRAT we were able to determine and see the result of which interval the target failure would be hit at. Failure rate helps us and others who use it determine how much we need to increase our testing or if the SUT would need to be changed. Failure rate allows us to also see the number of failures that end-users who would be using the application would experience. Our goal for the target was to determine the lowest possible rate that would ensure that the application is still reliable and that the tool will be able to predict. With this knowledge, we were able to predict and aim for a target failure rate of 1.8 for our given report and SUT.  With this target failure rate, the failure data for the system under test we can determine that the SUT is not a reliable system with this high of a failure rate. 

**A discussion on the advantages and disadvantages of reliability growth analysis:**
Advantages:
  - The graphs that are produced through this method, provide insight on time-dependant trends and allows us to predict failure results based on the data we  provide it
  - We can easily see and analyze how many failures are produced through a certain amount of time as well as how intense these are 
  - It is easy to determine and examine the changes at a specific point in time from the results of a reliability growth analysis, this allows us to determine acceptable failure rates and to determine if the SUT is a reliable system with the amount of failures that are produced. 

Disadvantages
  - It is very tedious to create these graphs as we need to format the data that was given to us in acceptable way for each tool that would be used
  - Using different tools with the same data brings different results for the graphs and some tools would not produce results 
  - Prediction results can differ based on different models used which can affect if the SUT could be determined reliable or not. 


# Assessment Using Reliability Demonstration Chart (Part 2)

# 

# Comparison of Results

# Discussion on Similarity and Differences of the Two Techniques

# How the team work/effort was divided and managed

# 

# Difficulties encountered, challenges overcome, and lessons learned

# Comments/feedback on the lab itself
